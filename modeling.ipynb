{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb0ee4ac2782390",
   "metadata": {},
   "source": [
    "# Codificador Automático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e704a8c041bda757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    LSTM,\n",
    "    Input,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "plt.style.use([\"science\", \"ieee\", \"notebook\"])\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ea2833f063b79290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_to_sequence(folder_path: str, window_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Função usada para converter os dados .csv de uma pasta\n",
    "    para o formato aceito pelo autocodificador LSTM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path: str\n",
    "        Caminho (pasta) em que os dados estão localizados.\n",
    "\n",
    "    window_size: int\n",
    "        Tamanho da janela de dados que o modelo receberá.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array contendo as sequencias na forma de sequencias\n",
    "    \"\"\"\n",
    "\n",
    "    X = None\n",
    "\n",
    "    for filename in tqdm(os.listdir(\"data/\" + folder_path)):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            df_old = pd.read_csv(\"data/\" + folder_path + \"/\" + filename)\n",
    "            df = calibrator.apply_calibration(df_old)\n",
    "            sequences = df_to_sequence(df.PT105, window_size)\n",
    "            if X is None:\n",
    "                X = sequences\n",
    "            else:\n",
    "                X = np.concatenate((X, sequences))\n",
    "    return X\n",
    "\n",
    "\n",
    "def df_to_sequence(data: pd.DataFrame, window_size: int) -> np.ndarray:\n",
    "    x = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        row = [[r] for r in data[i : i + window_size]]\n",
    "        x.append(row)\n",
    "\n",
    "    return np.array(x)\n",
    "\n",
    "\n",
    "def train_test_split_ae(\n",
    "    sequence: np.ndarray, test_size: float =0.25, shuffle: bool =True\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Função responsável por dividir o conjunto de dados em \n",
    "    treino e validação baseado em uma fração `test_size`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence: np.ndarray\n",
    "        Sequência a ser dividida..\n",
    "\n",
    "    test_size: float\n",
    "        Fração que representa o tamanho do conjunto de \n",
    "        validação em relação ao tamanho da sequencia de \n",
    "        entrada\n",
    "\n",
    "    shuffle: bool\n",
    "        Se os conjuntos são embaralhados ou não.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np.ndarray, np.ndarray]\n",
    "        Os valores na ordem Xtrain, Xtest\n",
    "    \"\"\"\n",
    "    n_samples = len(sequence)\n",
    "\n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(n_samples)\n",
    "    else:\n",
    "        idx = np.arange(n_samples)\n",
    "\n",
    "    test_set_size = int(n_samples * test_size)\n",
    "    test_idx = idx[:test_set_size]\n",
    "    train_idx = idx[test_set_size:]\n",
    "\n",
    "    X_train = sequence[train_idx]\n",
    "    X_test = sequence[test_idx]\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c5ce4f09-8f92-4d97-b65f-34b0ca93176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calibrator:\n",
    "    def __init__(self):\n",
    "        files = [\"PT105\"]\n",
    "        self.data: dict = {}\n",
    "        for filename in files:\n",
    "            df = pd.read_csv(\n",
    "                f\"data/calibracao/{filename}.csv\", delimiter=\",\", decimal=\",\"\n",
    "            )\n",
    "            x, y = df.iloc[:, 0], df.iloc[:, 1]\n",
    "            self.a, self.b = np.polyfit(x, y, 1)\n",
    "            self.data[filename] = (self.a, self.b)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.data)\n",
    "\n",
    "    def apply_calibration(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df[\"PT105\"] = self.a * df[\"cDAQ1Mod1/ai2\"] + self.b\n",
    "        return df\n",
    "\n",
    "class MinMaxScaler_AE:\n",
    "    def __init__(self):\n",
    "        self.min_val: list[float] = None\n",
    "        self.max_val: list[float] = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"min: {self.min_val}\\nmax: {self.max_val}\\n\"\n",
    "    \n",
    "    def fit(self, X_train):\n",
    "        \"\"\"\n",
    "        Ajusta o scaler com base nos valores mínimos e máximos do conjunto de treino.\n",
    "        \n",
    "        Args:\n",
    "            X_train (numpy array): Dados de treino.\n",
    "        \"\"\"\n",
    "        self.min_val = np.min(X_train, axis=0)\n",
    "        self.max_val = np.max(X_train, axis=0)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforma os dados com base nos mínimos e máximos calculados no treino.\n",
    "        \n",
    "        Args:\n",
    "            X (numpy array): Dados a serem normalizados.\n",
    "        \n",
    "        Returns:\n",
    "            X_scaled (numpy array): Dados normalizados entre 0 e 1.\n",
    "        \"\"\"\n",
    "        return (X - self.min_val) / (self.max_val - self.min_val)\n",
    "    \n",
    "    def inverse_transform(self, X_scaled: np.ndarray) -> np.ndarray:\n",
    "        return X_scaled * (self.max_val - self.min_val) + self.min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ae4b236502d9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator = Calibrator()\n",
    "scaler = MinMaxScaler_AE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fde582-c081-45c2-b17d-b453b01cd680",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "bigX = folder_to_sequence(\"VIDRO-B3\", window_size=window_size)\n",
    "print(\"data shape: \", bigX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d13791e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval = train_test_split_ae(bigX)\n",
    "scaler.fit(Xtrain)\n",
    "\n",
    "Xtrain_N, Xval_N = scaler.transform(Xtrain), scaler.transform(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "816cf6b4-a03a-4bfa-b0e9-7f2d93fb2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste 1\n",
    "autoencoder = Sequential(\n",
    "    [\n",
    "        Input((None, 1)),  # Indica que as séries temporais são de apenas uma feature\n",
    "        LSTM(window_size // 2, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        RepeatVector(window_size),\n",
    "        LSTM(window_size // 2, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(1)),\n",
    "        Flatten(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5620a6-e6b6-4d07-8e49-3e3b22f3b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8952b8-1f0f-4249-9df4-7d1c9b68445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\",\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=20, min_lr=1e-5\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=80, verbose=1),\n",
    "]\n",
    "\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss=\"mse\")\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    Xtrain_N,\n",
    "    Xtrain_N,\n",
    "    validation_data = (Xval_N, Xval_N),\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775810a-028f-4815-a4ea-44fd1ec381f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = np.arange(1, len(loss) + 1)\n",
    "\n",
    "plt.yscale(\"log\", base=10)\n",
    "plt.plot(epochs, loss, c=\"k\", label=\"Treino\", lw=3)\n",
    "plt.plot(epochs, val_loss, c=\"grey\", label=\"Validação\", lw=3)\n",
    "plt.scatter(\n",
    "    np.argmin(val_loss), np.min(val_loss), label=f\"Mínimo = {np.min(val_loss):.2E}\"\n",
    ")\n",
    "plt.ylabel(\"Erro Médio Quadrático\")\n",
    "plt.xlabel(\"Iteração de Treino\")\n",
    "plt.xlim((0, len(loss)))\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"images/curva-de-aprendizdo.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb883f-69c2-4849-a2fe-a4ede561d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(Xtrain_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073a18e-4fbf-4be8-9859-1a95f5a1c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "index: int = window_size*4\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(Xtrain_N[index])\n",
    "plt.plot(predictions[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
